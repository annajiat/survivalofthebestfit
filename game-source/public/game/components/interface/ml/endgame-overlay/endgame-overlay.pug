include ../../ui-overlay/ui-overlay.pug
include ../../../universal/button/button
script(src='../scripts-website.min.js')
+overlay()(id="js-endgame-overlay" class="EndgameOverlay")
	
	.conversationBox
		.conversation-container
			#part1
				h3 Taking A Step Back
				img.center-block(src='assets/img/sotbf-manual.gif')

				p As a recruiter, which of these attributes did you value the most?

				#buttons
					div(class="button button__choice" onclick="select(this)")
						p Education

					div(class="button button__choice" onclick="select(this)")
						p Experience

					div(class="button button__choice" onclick="select(this)")
						p Ambition

					div(class="button button__choice" onclick="select(this)")
						p Skills

			#part2

				p(style="float: left") When the engineering team contacted you, they asked you for <i> your </i> decisions, in <b> cv_all.zip </b>, because software requires human input. <br>

				p That means if you had biases, the software would replicate them, and if you were careless, the outputs would be messy! But what if you were as objective as you could be? <br>

				div(class="button button__proceed" onClick="next1()")
					p(style="font-size: 1.2rem") NEXT

			
			#part3
				
				h3 Training the Algorithm

				p Your data alone wasn't enough to build a machine learning (ML) algorithm, because ML only works on large amounts of data, so you were asked to choose a larger dataset. The problem is, these historical datasets can have all sorts of inequalities built in. <br>

				img.center-block(src='assets/img/sotbf-training.gif')

				p In this case, it largely consisted of applicants from Orange Valley, where more people were historically allowed to work in tech. In the real world, this could mean your data reflects a history of injustice, like favoring a certain race, gender, or socio-economic background. <br> 

				p What if you ask your algorithm to disregard looking at these differentiators? <br>

				div(class="button button__proceed" onClick="next2()")
					p(style="font-size: 1.2rem; color: white") NEXT

			
			#part4

				h3 Behind the Code

				p There is no on-off switch to ask automated decision-making programs to do the right thing. In hiring, for example, it's not just that data is categorized by race or gender, but that it also represents the colleges, societies, and organizations certain demographics were allowed to be a part of. <br>

				img.center-block(src='assets/img/sotbf-automated.gif', style="width: 60%; margin-right: auto; clear: right; margin-top: 3%;")

				p When a program learns from years of data, we need to question the data it is learning from. Just because a decision is presented as 'automated' doesn't mean it is right or objective. <br>

				p Your startup Bestfit might've failed today, but there's no reason our societies should! Head to our website to learn more. We hope it'll make you discuss and ask questions. <br>

				.button-row
					div(class="button button__proceed")
						a(href='https://www.survivalofthebestfit.com/resources' onClick="goToResourcesLog()") BECOME AN EXPERT
					
					//- share buttons
					//- a(href="https://www.facebook.com/sharer.php?u=https://survivalofthebestfit.com", target="_blank")
					//- 	img(src="https://4.bp.blogspot.com/-raFYZvIFUV0/UwNI2ek6i3I/AAAAAAAAGSA/zs-kwq0q58E/s1600/facebook.png" alt="Facebook" )
					//- a(href="https://twitter.com/share?url=https://survivalofthebestfit.com" target="_blank")
					//- 	img(src="https://4.bp.blogspot.com/--ISQEurz3aE/UwNI4hDaQMI/AAAAAAAAGS4/ZAgmPiM9Xpk/s1600/twitter.png" alt="Twitter")