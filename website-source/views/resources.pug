extends ./layout/layout-default.pug

block content
	script(src='../scripts-website.min.js')
	body(class="resources")
		
		h1 Software, Bias, and Justice
		div#info
			div#text1

				h4.header-box BREAKING DOWN THE TECH

				p.info-box You don't need to be a programmer or engineer to question the tech affecting your - and all of our - lives. The goal isn't necessarily for everyone to start building AI, though the field can certainly use <a style="text-decoration-line: underline; color:#BE5E5E" href='trial.html'> more diversity</a>, but to have enough awareness to be able to ask important questions! <br> <br> Besides being a highly popular startup buzz-word, <a style="text-decoration-line: underline; color:#BE5E5E" href='https://www.youtube.com/watch?v=z-EtmaFJieY'> Machine learning (ML)</a>, is an application of artificial intelligence (AI) that deals with teaching computers how to make decisions by learning from large amounts of data. This can be powerful and useful, but it is important to remember that just because a decisions is 'automated', doesn't mean it has to be correct, objective, or fair. <br> <br> When building automated decision-making systems, we should be asking: what metrics are these decisions based on, and who can we hold accountable? With machine learning, that becomes tricky, because after the program is trained on pre-existing data, finding out <i> why </i> a certain decision was made isn't straightforward. It's what is referred to as the <b> Black Box problem</b>. <br> <br> Technology should help us move forward, and not repeat the mistakes of the past. If the data we use, for example, is of a time when only people of a certain race, gender, or class are privelged by the system, then what are we teaching our software? 


					h4.next-box(onclick='open1()') NEXT: HOW DO WE FIX IT?		
	
			div#text2

				h4.header-box HOW DO WE FIX IT?		

				p.info-box The short answer is: we don't have an answer yet. One of the main problems with using software to make important decisions is that you often can’t track down why a decision was made. In machine learning, this is what is often referred to as the “black box problem”. A software would learn from data and try to replicate it, but it does not let you know specifically what that decision-making process looks like. In cases where software solutions would make it impossible to hold corporations and governments accountable, it may be a better option to refrain from using them at all. <br> <br> The solution to bias is not straightforward. It might be easy to think that to fix bias in the dataset, all we need to do is to gather a representational dataset. Since machine learning works on mass data, however, this may still not help minorities. Navigating bias and representation is a complex topic, and so is fairness. If we want to build equitable software systems that do not discriminate against or disadvantage any members of our society, we must open up this conversation to people who are not software engineers, or in the tech industry. 

					h4.next-box(onclick='open2()') NEXT: TAKING STEPS FORWARD
					h4.next-box(style="float: left; margin-left: 5%;" onclick='back()') BACK	


			div#text3

				h4.header-box TAKING STEPS FORWARD

				p.info-box <b> Education and Awareness </b> <br> <br> We believe that the first step to achieving real progress is to engage in research and conversation with groups and individuals both within and outside the technical field, such as policy-makers, lawyers, social scientists, and advocacy groups. We need to gain a better understanding of how to navigate fairness, bias, and equity in the digital world. For that to be possible, we must work on bridging the technical gap. We want issues in tech ethics to be accessible to those who may have not taken a computer science class before, but still have a lot to add to the conversation. <br> <br> <b> Ethical Frameworks </b> <br> <br> While we think people outside of tech should be involved, we want tech companies and software developers to make an effort too. This means making discussions about ethics be a conscious part of the software development process. <br><br> Institute for the Future and Omidyar Network worked on <a href='https://ethicalos.org/wp-content/uploads/2018/08/Ethical-OS-Toolkit.pdf')>Ethical OS</a>, “a guide to anticipating the future impact of today’s technology”.  <br> <br> AI Now Institute, based at NYU, have also worked on an <a href='https://ainowinstitute.org/aiareport2018.pdf')> Algorithmic Impact Assessment </a> guide aimed at public agencies, with the aim of providing a practical framework to assess automated decision systems. 

				h4.next-box(style="float: left; margin-left: 5%;" onclick='back()') BACK	