extends ../layout/layout-default.pug

block content
	script(src='../scripts-website.min.js')
	body(class="resources")
		
		h1 On Socially Responsible AI
		div#info
			div#text1

				h4.header-box MACHINES & BIAS

				p.info-box Bias has long been a concern in recruiting. One might think that computers can help us eliminate this human bias, but automation is not always the answer. Since ‘machine learning’ algorithms work by learning from previous trends, automated decision-making inherit the bias already existing in its given data. For example, if you teach a computer to learn from the past century of successful CVs, it can pick on trends that reflect historical and societal inequalities.

					h4.next-box(onclick='open1()') NEXT: HOW DO WE FIX IT?		
	
			div#text2

				h4.header-box HOW DO WE FIX IT?		

				p.info-box The short answer is: we don't have an answer yet. One of the main problems with using software to make important decisions is that you often can’t track down why a decision was made. In machine learning, this is what is often referred to as the “black box problem”. A software would learn from data and try to replicate it, but it does not let you know specifically what that decision-making process looks like. In cases where software solutions would make it impossible to hold corporations and governments accountable, it may be a better option to refrain from using them at all. <br> <br> The solution to bias is not straightforward. It might be easy to think that to fix bias in the dataset, all we need to do is to gather a representational dataset. Since machine learning works on mass data, however, this may still not help minorities. Navigating bias and representation is a complex topic, and so is fairness. If we want to build equitable software systems that do not discriminate against or disadvantage any members of our society, we must open up this conversation to people who are not software engineers, or in the tech industry. 

					h4.next-box(onclick='open2()') NEXT: TAKING STEPS FORWARD
					h4.next-box(style="float: left; margin-left: 5%;" onclick='back()') BACK	


			div#text3

				h4.header-box TAKING STEPS FORWARD

				p.info-box <b> Education and Awareness </b> <br> <br> We believe that the first step to achieving real progress is to engage in research and conversation with groups and individuals both within and outside the technical field, such as policy-makers, lawyers, social scientists, and advocacy groups. We need to gain a better understanding of how to navigate fairness, bias, and equity in the digital world. For that to be possible, we must work on bridging the technical gap. We want issues in tech ethics to be accessible to those who may have not taken a computer science class before, but still have a lot to add to the conversation. <br> <br> <b> Ethical Frameworks </b> <br> <br> While we think people outside of tech should be involved, we want tech companies and software developers to make an effort too. This means making discussions about ethics be a conscious part of the software development process. <br><br> Institute for the Future and Omidyar Network worked on <a href='https://ethicalos.org/wp-content/uploads/2018/08/Ethical-OS-Toolkit.pdf')>Ethical OS</a>, “a guide to anticipating the future impact of today’s technology”.  <br> <br> AI Now Institute, based at NYU, have also worked on an <a href='https://ainowinstitute.org/aiareport2018.pdf')> Algorithmic Impact Assessment </a> guide aimed at public agencies, with the aim of providing a practical framework to assess automated decision systems. 

				h4.next-box(style="float: left; margin-left: 5%;" onclick='back()') BACK	